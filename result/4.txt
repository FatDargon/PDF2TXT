 神经评定回归与抽象技巧代的生成 
 数据科学实验室，京东方，北辰世纪中心， 
 摘要最近，一些电子商务网站在其移动应用上推出了一个名为Tips的新交互框。用户可以表达他们的经验和感受，或者使用短文本提供建议，典型的是几个字或一个句子。实质上，编写一些提示并给出数字评分是用户产品评估行为的两个方面，表达用户体验和感受。联合建模这两个方面有助于设计更好的推荐系统。尽管一些现有的模型将诸如项目规格或用户评论之类的文本信息整合到用户和项目潜在因素中以改进评级预测，但现有作品没有考虑提高推荐质量的提示。我们提出了一个名为NRT的深度学习框架，它可以同时预测精确的评分和生成抽象技巧，并具有良好的语言质量，模拟用户体验和感受。对于抽象技巧的产生，采用门控递归神经网络将用户和项目潜在表示“翻译”为简明句子。对来自不同领域的基准数据集进行的大量实验表明，相对于最先进的方法，NRT实现了显着的改进。此外，生成的提示可以生动地预测用户的体验和感受。 
 CCS概念•信息系统→信息检索;推荐系统;协同过滤; 
 *本文所描述的工作得到中国香港特别行政区研究资助委员会（项目代码：14203414）和微软研究院亚洲城市信息学拨款FY14-RES-Sponsor-057的资助。这项工作也与中大人力中心计算和接口技术部门的微型重点实验室有关。 
 允许将个人或课堂使用的全部或部分作品的数字化或硬拷贝免费授予，前提是复制品不是为了获利或商业利益而制作或发布的，并且副本在第一页上包含本通知和全部引用。必须尊重他人拥有的作品组成部分的版权。允许用信用抽象。要复制或重新发布，在服务器上发布或重新分发到列表，需要事先获得特定许可和/或收费。请求permissions@acm.org的权限。 SIGIR '17，2017年8月7日 -  11日，日本东京新宿©2017版权属于作者/作者。授权给计算机械协会的出版权。 ACM ISBN 978-1-4503-5022-8 / 17/08 ... $ 15.00 https://doi.org/10.1145/3077136.3080822 
 图1：从Yelp餐厅“Gary Danko”中选择的评论和提示示例。提示比评论更简洁，只需几句话就可以揭示用户体验，感受和建议。用户在使用手机扫描提示后立即得到有关该餐厅的结论。 
 关键词评级预测;提示生成;深度学习。 
 1引言随着互联网信息的爆炸性增长，推荐系统在各种领域的在线电子商务和应用中扮演着越来越重要的角色，其中包括Spotify1和Apple Music等音乐流媒体服务，IMDB2等电影评级，Netflix和Youtube等视频流媒体服务，LinkedIn3等工作推荐以及亚马逊等产品推荐。许多推荐方法基于主要使用的协作过滤（CF） 
 1http：//www.spotify.com 2http：//www.imdb.com 3http：//www.linkedin.com 
 TipsReview的历史收视率[14,15,18,22,31,33,35]。最近，除了评分数据外，一些方法还考虑了文本信息[1,21,23,26,40,49]。经过一些调查后，我们发现大多数推荐任务中的文本信息通常可以分为两类：项目规范[40-42]和用户评论[1,21,23,26,46,47,49]。项目规格是用于描述项目的属性或属性的文本信息。例如，在诸如CiteULike4的文章推荐中，它指的是论文的标题和摘要。在诸如亚马逊的产品推荐中，它指的是产品说明和技术规格信息。第二种是由用户编写的用户评论，用于解释他们为什么喜欢或不喜欢基于他们的使用体验的项目。可以从评论中提取多方面的信息，并将其用作用户偏好或项目特征，否则无法从总体评分中获得[5]。虽然这两种类型的文本数据都被认为对推荐任务有用，但它们有一些固有的局限性。具体而言，前者不能反映用户的经验和偏好，后者通常太长而且会受到噪音的影响。 
 最近，一些电子商务网站（例如Yelp5）在其移动平台上推出了一个名为Tips的新交互框。如图1所示，左栏是来自用户“Monica H.”的评论，并且来自其他几位用户的提示显示在右栏。在评论文章中，莫妮卡首先介绍了餐厅，然后详细叙述了她的用餐体验。在提示文字中，用户使用简短的文字简单地表达了他们的经验和感受，例如“烩饭很棒。令人惊叹的服务。“他们还用几个词直接向其他人提供了一些建议，例如“您必须提前预约”。与项目规格和用户评论相反，提示有几个特点：（1）提示通常是单一主题块的信息，比平均长度约10字的评论短; （2）提示可以直接表达用户体验，感受和建议; （3）提示可以给其他人快速的见解，节省阅读长篇评论的时间。实质上，编写一些提示并给出数字评分是用户产品评估行为的两个方面，表达用户体验和感受。联合建模这两个方面有助于设计更好的推荐系统。 
 现有模型仅集成文本信息，如项目规范[40-42]和用户评论[1,21,23,26,46,47,49]，以提高潜在因素建模和评级预测的性能。据我们所知，我们是第一个考虑提高推荐质量的技巧。我们的目标是开发一个能够进行潜在因素建模和评级预测的模型，更重要的是，它可以根据学习到的潜在因素生成提示。我们不只是提取一些现有的句子，并将它们视为提示。相反，我们调查自动将简洁句子作为提示的任务，这样的能力可以被看作是模拟用户如何写技巧来表达他们的经验和感受，就好像他们已经购买和使用了该项目一样。因此，我们将这个任务命名为抽象化提示生成，其中“抽象”是文本摘要研究的术语[3]。 
 仅基于用户潜在因素和项目潜在因素生成抽象提示是一项具有挑战性的任务。最近，诸如长期短期记忆（LSTM）[12]和门控循环单元（GRU）[6]等门控循环神经网络在文本生成相关任务中表现出很高的能力[2,3]。此外，受[11,41]启发，基于神经网络的模型可以帮助学习更有效的潜在因素进行评级预测并提高协作过滤的性能。我们采用深度学习技术进行潜在因素建模，评分预测和抽象提示生成。对于抽象技巧的产生，采用门控递归神经网络将用户潜在因素和项目潜在因素“翻译”为简明句子以表达用户体验和感受。对于神经评分回归，多层感知器网络[28]被用来将用户潜在因素和项目潜在因素投影到评分中。门控递归神经网络和多层感知器网络中的所有神经参数以及用户和项目的潜在因素都是通过多任务学习方法在端到端训练范例中学习的。我们框架的主要贡献总结如下：•我们提出了一个名为NRT的深度学习框架，它可以同时预测精确的评分，并生成具有良好语言质量的抽象技巧，模拟用户体验和感受。所有神经参数以及用户和项目的潜在因素都是通过多任务学习方法在端到端培训范例中学习的。 •我们是第一个探索使用提示信息来提高推荐质量的人。实质上，编写一些提示并给出数字评分是用户产品评估行为的两个方面，表达用户体验和感受。联合建模这两个方面有助于设计更好的推荐系统。 •基准数据集上的实验结果表明，我们的框架在评估预测和抽象提示生成任务上的性能均优于最先进的模型。 
 2相关工作协同过滤（CF）已经进行了很长时间的研究，并在推荐系统中取得了一些成功[27,37]。基于矩阵分解（MF）的隐性因子模型（LFM）[15]对评级预测起着重要作用。已经提出了各种MF算法，例如奇异值分解（SVD）和SVD [14]，非负矩阵分解（NMF）[18]和概率矩阵分解（PMF）[31]。这些方法将用户和项目映射到共享的潜在因素空间，并分别使用潜在特征向量作为用户和项目的表示。那么它们的潜在因素向量的内积可以反映用户和项目之间的交互作用。 
 当评级矩阵非常稀少时，推荐性能会显着降低。因此，一些作品考虑改进评级预测的文本信息。项目规格和用户评论都已被调查。为了使用项目规范，CTR [40]将PMF [31]和潜在Dirichlet分配（LDA）[4]集成到一个框架中，并采用LDA对文本进行建模。协作深度学习（CDL） 
 [41]采用分层贝叶斯模型，联合执行规范文本内容的深度表示学习和评级矩阵的协同过滤。对于用户评论文本，一些研究工作，如HFT [23]，RMR [21]，TriRank [10]和sCVR [26]将主题模型整合到其框架中，以为用户和项目生成潜在因素， 。此外，TriRank和sCVR已经明确声称他们可以提供对建议的解释。然而，它们的一个共同的局限是它们的解释是从文本中简单提取单词或短语。相比之下，我们的目标是生成简洁的句子，代表提示，表达用户在审阅项目时的感受。 
 深度学习（DL）技术在计算机视觉，语音识别和自然语言处理领域取得了显着的成功[8]。在推荐系统领域，研究人员通过将不同的神经网络结构与协作过滤结合起来以提高推荐性能做了一些尝试。 Salakhutdinov等人。 [32]采用一类具有高效学习算法的双层受限玻尔兹曼机器（RBM）来建模用户交互并执行协作过滤。考虑到Auto-Encoders [25]的训练过程更直接，一些研究工作采用自动编码器来处理潜在因素建模和评分预测[34,39,44]。最近，他等人。 [11]结合广义矩阵分解和多层感知，从用户交互中找到更好的潜在结构，以提高协作过滤的性能。为了模拟用户交互中的时间动态信息，Wu等人[43]提出一个能够预测未来行为轨迹的反复推荐网络。 
 3框架描述3.1概述推荐的目标与协作过滤类似，是预测给定用户和项目的评分。另外，在我们提出的任务中，我们的模型还以简明的句子的形式生成抽象提示。在操作阶段，只有用户和物品被给出。没有给出评论文本，也没有明显的提示文本。 
 在培训阶段，培训数据由用户，项目，提示文本和评论内容组成。表1描述了我们论文中使用的符号和关键概念。我们用X = {U，I，R，C，S}来表示整个训练语料库，其中U和I分别是用户和项目集合，R是评级集合，C是评审文档集合， S是提示句子的集合。如图2所示，我们的框架包含两个主要组件：左侧的神经评分回归和右侧的抽象提示生成。有两个关键的潜变量：用户潜在因素U∈Rku×m和项目潜在因素V∈Rkv×n，其中m是用户数量，n是项目数量。 ku和kv分别是用户和项目的潜在因素维度。对于神经评分回归，给定用户潜在因子u和项目潜在因子v，采用基于多层感知器网络的回归模型，通过几层非线性变换将u和v投影到实际值。 
 描述训练集词汇集用户集评价集评论集提示上下文提示解码器用户潜在因素项目潜在因素词嵌入神经隐藏状态用户潜在因素项潜在因素映射矩阵偏倚项目集神经参数评级用户u至项目j sigmoid函数softmax函数双曲正切函数 
 符号X V U I R C S Cctx U V E H u v W bΘru，iσςtanh 
 对于抽象提示的生成，我们设计了一个基于门控循环神经网络的序列解码模型，称为门控循环单元（GRU）[6]，以将用户潜在因子u和项目潜在因子v的组合转化为字，代表小费。而且，基于u和v生成的两种上下文信息也被输入到序列解码器模型中。一个是来自评级回归组件的隐藏变量，其被用作情感上下文信息。另一个是审查文本生成模型的隐藏输出。在操作或测试阶段，我们使用波束搜索算法[13]来解码并生成给定训练模型的最佳提示。用户，项目和单词的所有神经参数和潜在因素都是通过多任务学习方法学习的。该模型可以通过使用反向传播算法的端到端范式有效地进行训练[29]。 
 3.2神经评分回归神经评分回归组件的目的是对用户因子u和上述项目因子v进行表示学习。为了预测评分，我们需要设计一个可以学习函数fr（·）的模型，该函数可以将u和v投影到实值评分r： 
 （1）在大多数现有的潜在因素模型中，fr（·）由u和v的内积表示，或者分别为相应的用户和项目添加一个偏差项： 
 （2）显然，评级是通过用户潜在因素，项目潜在因素和偏差的线性组合来计算的。学到的潜伏 
 图2：我们提出的用于评分回归和抽象提示生成的框架NRT。 
 因素可能无法捕捉用户历史交互中隐含的复杂结构。最近，有关计算机视觉[9,16]，自然语言处理[17,24]和知识库完成[36]等不同领域的表征学习的研究表明，非线性变换将提高表示能力。此外，大多数潜在因素模型假定用户和项目甚至文本信息处于相同的向量空间并共享相同的潜在因素。实际上，用户，项目和文本信息是具有不同特征的不同种类的对象。在相同的向量空间中对它们进行建模将导致限制。如图2左侧所示，我们让用户潜在因素U∈Rku×m和项目潜伏因子V∈Rkv×n在不同的向量空间中，其中ku和kv分别是用户和项目的潜在因素维度。 m和n分别是用户和项目的数量。为了建模用户和项目之间的关系，可以考虑使用神经张量网络[36]来描述用户和项目之间的交互，比如uT Wv，其中W∈Rku×d×kv。然而，我们的调查显示，这样的张量网络参数太多，导致难以处理推荐应用中常见的大规模数据集。因此，我们使用多层感知器网络来模拟用户和项目之间的交互，并将用户潜在因素和项目潜在因素映射为实值评分。具体而言，我们首先将潜在因素映射到共享隐藏空间： 
 uhu Wr（3）vh∈Rd×kv分别为用户潜在因子和项潜在因子的Wr h∈Rd的映射矩阵。 br是偏见术语。 d是隐藏向量hr的维数。上标r是指与评级预测组件相关的变量。 σ（·）是S形激活函数： 
 这种非线性转换可以提高评级预测的性能。为了获得更好的性能，我们可以在模型中添加更多非线性变换层：） 
 （5）∈Rd×d是Wr隐藏层变量的映射矩阵。 l是隐藏层的索引。假设hr L是最后一个隐藏层的输出。输出层将hr L转换为实数值r： 
 为了优化潜在因子U和V以及所有神经参数Θ，我们将其表述为回归问题，并将损失函数表示为： 
 （7）其中X代表训练集。 ru，i是用户u为项目i分配的地面实况评分。 3.3神经抽象技巧的产生仅基于用户潜在因素和项目潜在因素来产生抽象技巧是一项具有挑战性的任务。如上所述，抽象提示的生成不同于评论内容摘要和可解释的主题词提取。在操作阶段，输入只包含用户和项目，但没有任何文本信息。在从矩阵U和V中获得用户潜在因子u和项目潜伏因子v之后，我们应该设计一种策略来将这两个潜在向量“翻译”为流畅的单词序列。最近，诸如长期短期记忆（LSTM）[12]和门控循环单元（GRU）[6]等门控循环神经网络在文本生成相关任务中表现出很高的能力[2,3]。受这些作品的启发，考虑到GRU具有可比较的性能，但参数较少且计算更有效，因此我们将GRU作为我们的基本模型 
 log（）wSpw（cid：143）（cid：16）（cid：166）2（）rr（cid：16）Reallygoodpizza！<eos> Reallygoodpizza！UserItemRating RegressionAbstractive Tips GenerationRatingUVEctxCReviewTips：序列建模框架。图2的右侧部分描述了我们的提示生成模型。 
 提示生成的序列建模的主要思想可以是 
 （8）其中st是提示s的第t个词。 Cctx表示将在下面的章节中描述的上下文信息。 ς（·）是softmax函数，定义如下： 
 hs t是时间t的序列隐藏状态，它取决于时间t和前一个隐藏状态hs的输入 
 （10）这里f（·）可以是香草RNN，LSTM或GRU。在GRU的情况下，状态更新按照以下操作进行处理： 
 t =σ（Ws rs t =σ（Ws zs t = tanh（Ws gs t⊙hs hs t = zs 
 sr st Ws hr hs szst Ws hzhs shst Ws t-1（1  -  zs 
 r）t-1 bs z）t-1 bs hh（rs t⊙hs t）⊙gs 
 其中st∈E是提示词st的嵌入向量，向量也是从我们的框架中学习到的。 rs t是重置t是更新门。 ⊙表示单元乘法。门，zs tanh是双曲正切激活函数。如图2所示，当t = 1时，序列模型没有输入信息。因此，我们利用上下文信息Cctx来初始化hs 0.上下文信息在序列解码框架中非常关键，这将直接影响序列生成的性能。在神经机器翻译领域[45]，上下文信息包括源输入的编码信息和来自源的解码关注信息。在神经汇总领域[19,30]，上下文是编码文档信息。在我们的框架中，相应的用户u和项目i是我们设计两种用于提示生成的上下文信息的输入：预测评分ru，i以及针对评论文本hc L生成的隐藏变量。 
 对于输入，我们只需找到用户潜在因素和项目 
 （12）对于评级信息的情况，我们可以使用3.2节中评级回归组件的输出。具体来说，在获得预测评分ru后，例如，ru，i = 4.321，我们将其转换为整数4，并添加一个向量化步骤。然后我们得到等级ru，i的向量表示。如果评分范围是[0，5]，我们将得到评分向量ru，i： 
 （13）ru，我用作上下文信息来控制生成提示的情绪。 
 另一个上下文信息来自评论文本。应该注意，评论文本不能直接用作输入。原因是在测试状态下，没有评论信息。我们只是利用评论来提高代表能力 
 的潜在向量U和V.我们为基于多层感知器的评论文本开发标准生成模型。对于由用户u写入项目i的评论内容cu，生成过程定义如下。我们首先将用户潜在向量u和项目潜在因子v映射到隐藏空间中：h）vhv bc 
 （14）很明显，我们还可以在生成的隐藏层中添加更多层的非线性变换。假设hc L是最后一个隐藏层的输出。我们将最终生成层L添加到| V |  - 大小矢量c中，其中V是在评论和提示中映射hc词的词汇表：c =ς（Wc 
 （15）hc∈R| V |×d和bc∈R| V |。 ς（·）是Softmax函数，其中Wc在方程9中定义。事实上，我们可以将c看作在V上定义的多项分布。因此，我们可以从c中画出一些单词并生成评论cu，i的内容。我们让c是cu，i的基本事实。 c（k）是cu，i中单词k的词频。我们使用可能性来评估这个生成过程的性能。为方便起见，我们使用负对数似然（NLL）作为损失函数： 
 我们模型设计的一个特点是评级和评论文本都是从相同的用户潜在因素U和项目潜在因素V生成的，即U和V由评级预测和评论文本生成的子任务共享。因此，在训练阶段，U和V都收到来自所有子任务的反馈，这提高了潜在因素的表示能力。 L}，我们使用c）bs 
 将它们整合成初始解码隐藏状态hs非线性变换： 
 在获得所有上下文信息Cctx = {r，hc 
 （17）其中u是用户潜在因子，v是项目潜在因子，r是预测评分r的向量化，hc L是评论文本中生成的隐藏变量。然后GRU可以进行序列解码进度。在获得所有序列隐藏状态后，我们将它们馈送到最终输出层以预测提示中的单词序列。 
 （18）hs∈Rd×| V |和bs∈R | V |。 ς（·）是softmax函数，其中Ws在公式9中定义。然后，具有最大概率的字是步骤t 1的解码结果：* t 1 = arg max wi∈V 
 在训练阶段，我们也使用NLL作为损失函数，其中 
 算法1抽象抽头生成的光束搜索输入：光束尺寸β，最大长度η，用户标识u，项目标识v和 
 提示生成模型G.输出：β最佳候选提示。 1：初始化Π=∅，π[0：β-1] = 0，Πp=∅，πp= 0，t = 0; 2：获取用户潜在因素和项目潜在因素： 
 （i，u）和v = V（：，v）根据Π：{st}β-1 0生成β个新状态，对于i从0到βdo未完成序列si←Π（i）词{w0，w1，...。 。 。 ，wβ-1}←βargmax wi∈V为每个单词wj做 
 级联：Πp.inseart（si wj）（wj）似然性：πp.inseart（π[i] log s ti 
 结束得到最大似然度的顶级β序列： 
 =βargmaxs∈Πp，l∈πp，Πp=∅，πp= 0 
 {s}β-1Π←{s}β-1 14：0 t←t 1 15：16：结束，17：返回Π，π。 
 在测试阶段，给定一个训练好的模型，我们使用波束搜索算法来寻找具有最大对数似然性的最佳序列s *。 
 在算法1中示出了波束搜索算法的细节。 
 3.4多任务学习我们将评估预测和抽象技巧生成的所有子任务集成到一个统一的多任务学习框架中，其目标函数为：其中Lr是来自方程7的额定回归损失，Lc是来自方程16的评论文本生成损失，并且Lr是来自方程20的提示生成损失。Θ是神经参数的集合。 λr，λc，λs和λn是每个项的权重比例。整个框架可以使用端到端范例中的反向传播进行有效训练。 
 4实验设置4.1研究问题我们在本文中列出了我们希望研究的研究问题：•RQ1：NRT在评估预测任务中的表现如何？它是否超越了最先进的模型？ （见5.1节） 
 书电子电影
 •RQ2：NRT在抽象技巧生成中的性能如何？生成的提示可以表达用户体验和感受吗？ （见第5.2节）•RQ3：预测评级之间的关系是什么 
 和生成提示的情绪？ （见5.3节） 
 我们进行了广泛的实验来调查上述重新调查 
 搜索问题。 4.2数据集在我们的实验中，我们使用来自不同领域的四个标准基准数据集来评估我们的模型。这些数据集的评分是[0，5]范围内的整数。有三个来自Amazon 5-core6的数据集：Books，Electronics和Movies
 另一个数据集来自Yelp Challenge 20167.它也是一个由餐厅评论和提示组成的大型数据集。用户数量为684,295，是所有数据集中最大的。因此这个数据集也是最稀疏的一个。提示包含在数据集中。对于没有提示的样本，评论文本的第一句被提取并视为提示。我们在提示和评论文本中过滤掉低频率词汇，并为每个数据集建立一个词汇V.我们在表2中显示了我们的数据集的统计数据。4.3评估指标对于评估预测，我们使用两个指标：平均绝对误差（MAE）和均方根误差（RMSE）。它们都被广泛用于推荐系统中的评级预测。给定预测评分ru，i和地面实况评分ru，i来自用户u对于项目i，RMSE计算如下： 
 其中N表示用户和项目之间的评级数量。同样，MAE计算如下： 
 为了评估抽象尖端的生成，基本事实sh是用户为该项目编写的提示。我们使用ROUGE [20]作为我们的评估指标和标准选项8。这是一个经典的6http：//jmcauley.ucsd.edu/data/amazon 7https：//www.yelp.com/dataset_challenge 8ROUGE-1.5.5.pl -n 4 -w 1.2 -m -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 
 文本摘要领域的评估指标[3,20]。它会计算生成的提示与用户写入的基本事实之间的重叠单元数。假定s是生成的提示，n是n-gram，C（υn）是~s（sh或s）中n-gram的数量，Cm（дn）是s中共生的n-gram的数量和sh，那么s的ROUGE-N得分定义如下： 
 当~s = sh时，我们可以得到ROU GEr ecall，当~s = s时，我们得到ROU GEpr esicion。我们使用ROUGE-1（R-1），ROUGE-2（R-2），ROUGE-L（RL）和ROUGE-SU4（R-SU4）的Recall，Precision和F-measure来评估生成的提示。 
 4.4比较方法为了评估评级预测的性能，我们将我们的模型与以下方法进行比较：•RMR：评分满足评论[21]。它使用主题建模技术来对评论文本进行建模，并且与其他基于强主题建模的方法相比，实现了显着的改进。 •点击率：协作主题回归[40]。它是解决一类协同过滤问题的科学文章推荐的流行方法。请注意，点击率使用评分和项目规格。 NMF：非负矩阵分解[18]。它只使用PMF：概率矩阵分解[31]。引入高斯分布来模拟用户和项目的潜在因素。 •LRMF：学习用矩阵分解排序[35]。它将清单式学习到排序算法与矩阵分解相结合，以改进推荐。 •SVD：它通过考虑潜在因子建模的隐式反馈信息来扩展奇异值分解[14]。 •URP：用户评级轮廓建模[22]。主题模型被用来从生成角度对用户偏好进行建模。它仍然只使用评分矩阵作为输入。 
 对于抽象技巧的生成，我们发现没有现有的作品可以纯粹基于用户和项目的潜在因素生成抽象技巧。为了评估表现并与一些基线进行比较，我们对一些现有的方法进行了改进，使它们能够为提示生成提取句子，如下所示。 
 LexRank [7]是文本摘要领域的一种经典方法。我们添加一个预处理程序来准备LexRank的输入文本，其中包括以下步骤：（1）检索：对于用户u，我们首先从训练集中检索所有她的评论Cu。对于项目我，我们使用相同的方法来获得Ci。 （2）过滤：假设u和i的地面实况评级是ru，i，那么我们将删除Cu和Ci的所有评级，评级不等于ru，i。单词只出现在一组中的评论也被删除。 （3）提示提取：首先将Cu和Ci合并得到Cu，i，则该问题可以看作是一个多文档摘要问题。 LexRank可以从Cu，i中提取一个句子 
 表3：用于比较的基线和方法。 
 缩写词NRT评级预测RMR CTRM NMF PMF LRMF SVD URP提示生成LexRank CTRt RMRt 
 评分满足评论模型协作主题回归模型非负矩阵分解概率矩阵分解列表学习排名项目排名分解满足邻域用户评级轮廓建模使用LDA 
 用于摘要的Pagerank CTR提示主题提取RMR用于提示主题提取 
 作为最后的提示。请注意，我们利用这种方法的优点，因为使用了地面实况评分。 
 CTR包含主题模型组件，它可以为项目生成主题。因此，主题相关变量被用来提取提示：（1）我们首先得到项目i的潜在因子θi，并从θi中绘制出最大概率的主题z。然后从φz，这是一个关于V的z的多项分布，我们选择具有最大概率的前50个词。 （2）来自Cu的最类似的句子，我被提取为提示。该基线名为CTRt。另一个基准线方法RMRt是以相同的方式设计的。 
 最后，我们列出表3中的所有方法和基线。 
 4.5实验设置每个数据集分为三个子集：80％，10％和10％，用于培训，验证和测试。我们模型的所有参数都使用验证集进行调整。调整过程之后，我们将LRMF，NMF，PMF和SVD的潜在因子数设为k = 10。我们为使用主题模型的方法设置主题数量K = 50。在我们的NRT模型中，我们为用户潜在因素，项目潜在因素和词汇潜在因素设定K = 300。隐藏大小的尺寸为400.评级回归模型的层数为4，针尖生成模型为1.我们设置光束尺寸β= 4，最大长度η= 20。对于优化目标，我们让权参数λr=λc=λs= 1，λn= 0.0001。小批量训练的批量大小为200.隐层和RNN层中的所有神经矩阵参数均从[-0.1,0.1]之间的均匀分布初始化。 Adadelta [48]用于基于梯度的优化。我们的框架是在单一Tesla K80 GPU上通过Theano [38]实现的。 
 5结果和讨论5.1评级预测（RQ1）我们的框架NRT和所有数据集的比较模型的评级预测结果在表4中给出。它表明，我们的模型在所有数据集的MAE和RMSE指标下始终优于所有比较方法。从比较中， 
 表4：评级预测的MAE和RMSE值。 
 MAE 1.939 0.882 0.731 0.686 0.704 0.736 0.681 0.667 * 
 RMSE MAE 2.005 2.153 1.220 1.219 0.904 1.035 0.967 0.847 0.860 0.945 0.903 0.961 0.822 0.933 0.927 * 0.806 * 
 LRMF PMF NMF SVD URP CTR RMR NRT *统计显着性检验显示我们的方法优于RMR [21]。 
 RMSE MAE 1.977 2.203 0.927 1.612 0.794 1.297 1.194 0.745 0.764 1.126 0.854 1.154 0.741 1.123 1.107 * 0.702 * 
 RMSE MAE 1.809 2.189 1.320 1.290 1.062 1.135 1.049 1.020 1.030 1.006 1.174 1.069 0.994 1.005 0.985 * 0.985 * 
 RMSE 2.038 1.752 1.454 1.349 1.286 1.392 1.286 1.277 * 
 我们注意到基于主题建模的方法CTR和RMR比LRMF，NMF，PMF和SVD好得多。原因在于CTR和RMR考虑文本信息，例如项目规格和用户评论，以提高潜在因素的表示质量，而传统的基于CF的模型（例如LRMF，NMF，PMF和SVD）仅将评级矩阵视为输入。使用双尾配对t检验测试NRT和最佳比较方法RMR性能之间差异的统计显着性。结果显示NRT明显优于RMR。 
 除了联合学习提示解码器之外，我们没有对评论和提示的文本应用任何复杂的语言操作。联合建模提示信息对推荐性能已经非常有帮助。实际上，提示及其相应的评价是用户对产品评价的两个方面，即定性方面和定量方面。我们的NRT框架以其多任务学习模型优雅地捕捉了这些信息。因此学习的潜在因素更有效。 
 5.2抽象提示生成（RQ2）我们的NRT模型不仅可以解决评分预测问题，还可以生成抽象提示，模拟用户如何表达自己的体验和感受。我们的模型的提示生成和比较方法的评估结果在表5中给出。为了获得更多细节，我们报告了ROUGE-1，ROUGE-1和ROUGE-1的召回率，精确度和F-度量（百分比） 2，ROUGE-L和ROUGE-SU4。我们的模型在所有四个数据集中的精确度和F1度量指标中实现了最佳性能。关于电影的数据集
 对于大多数数据集，我们的NRT模型不会超过Recall基线。原因有以下几点：（1）训练集中使用的基本事实提示非常短，平均只有约10个字长。当然，使用这个数据集训练的模型不能产生长句。 （2）典型波束搜索算法的机制使得模型支持短句。 （3）比较模型是基于抽取的方法，这些模型有利于提取长句，尽管我们增加了一个长度（即20个字）的限制。 
 图3：验证集上波束大小β的有效性。 
 我们研究了波束搜索算法中使用的不同波束大小β的性能。电子与电影两套确认集上ROUGE与β的关系
 受到[45]的启发，我们利用长度归一化（LN）来调整波束搜索算法中的对数概率，以使波束搜索算法也考虑长句子： 
 其中s是解码序列，n = 2，并且α= 0.6。我们进行了几个实验来验证LN的有效性。比较结果显示在表9中，其中报告了ROUGE评估指标的F1-度量。很明显，我们的LN型NRT比没有LN的NRT好很多。 
 5.3案例分析（RQ3）为了分析预测评级与生成提示之间的语言质量和情感相关性，我们选择了一些来自不同领域的实际案例。结果列在表10中。虽然我们的模型以抽象的方式产生技巧，但技巧的语言质量相当好。 
 对于情绪相关性分析，我们也选择一些生成负面情绪的提示。以“不如我预期的那样好”作为例子，我们的模型预测评分为2.25，这清楚地表明了一致的情绪。基本事实 
 1234510200.1250.130.1350.140.1450.150.155β正规化的ROUGER-1R-2R-LR-SU41234510200.110.1150.120.1250.130.1350.140.1450.150.155β正规化的ROUGER-1R-2R-LR-SU4表5：对数据集Books的ROUGE评估。 
 表6：数据集电子学的ROUGE评估。 
 ROUGE-SU4 F1 R 4.13 4.02 3.80 4.49 3.99 4.71 3.24 4.13 
 ROUGE-SU4 R F1 3.88 4.57 3.97 5.41 3.89 5.39 4.51 4.68 
 ROUGE-SU4 R F1 3.75 4.47 3.28 4.63 3.36 4.88 6.04 6.33 
 ROUGE-SU4 R F1 3.26 3.41 3.72 3.88 3.70 3.96 3.01 3.78 
 表9：长度归一化（LN）的有效性。 R- *是指ROUGE- *。 
 R-1 NRT w / o LN 13.36 13.72电影
 这个例子的提示是“所有交易的杰克都没有。 “，这也传达了消极情绪。一个有趣的观察是它的地面实况评分是满分5，我们猜测，可能会被胖手指点击。尽管如此，我们的模型可以在这个案例的评级和提示之间产生一致的情绪。另一个生成的提示“什么是浪费时间和金钱”，负面预测评级为1.46也说明了这个属性。 
 也有一些不好的情况。例如，生成的提示“对价格不坏”的预测评级是4.34，这是a 
 正极性。但生成的提示的情绪是中性的，与实际情况一致。一般来说，我们的模型可以在评级预测和抽象提示生成方面取得令人满意的表现。 
 6结论我们提出了一个名为NRT的深度学习框架，它可以同时预测精确的评分和生成具有良好语言质量的抽象技巧，模拟用户体验和感受。对于抽象技巧的产生，具有上下文信息的GRU被用来将用户和项目潜在因素“翻译”成简明的句子。所有神经参数以及用户和项目的潜在因素都是通过多任务学习方法在端到端培训范例中学习的。基准数据集上的实验结果表明，在评估预测和抽象技巧生成两个任务上，NRT的性能均优于最先进的模型。生成的提示可以生动地预测用户体验和感受。 
 表10：预测评级和生成提示的示例。每组的第一行显示生成的评分和提示。第二行显示了事实。 
 这是一个伟大的产品，价格很高。伟大的产品在一个伟大的价格。我购买这个作为替代品，这是一个完美的结合，声音非常好。惊人的声音。我已经使用了几个月。大量的电线可以获得信号和功率给我的放大器，质量很好。我最喜欢的电影之一。这是一部不容错过的电影。为什么人们讨厌这部电影。通用为什么没有贵公司在1999年发布这个版本。不如我预期的那么好。所有行业的杰克都没有。真是浪费时间和金钱！科恩兄弟是两个生病的混蛋。价格不错。最终改变它以摆脱涟漪。 
 参考文献[1] Amjad Almahairi，Kyle Kastner，Kyunghyun Cho和Aaron Courville。从协作过滤评论中学习分布式表示。在RecSys中。 ACM，147-154。 
 [2] Dzmitry Bahdanau，Kyunghyun Cho和Yoshua Bengio。神经机器 
 通过共同学习来翻译和翻译。在ICLR。 
 [3]李东冰，皮吉利，廖一伟，林伟，郭薇薇，丽贝卡帕索诺。 2015年。通过短语选择和合并的抽象多文档汇总。在ACL中。 1587年至1597年。 
 [4] David M Blei，Andrew Y Ng和Michael I Jordan。潜在的狄利克雷分配。 
 [5]李晨，陈关良，王锋。基于用户评论的推荐系统：最先进的技术。 User Modeling and User-Adapted Interaction 25,2（2015），99-154。 
 [6] Kyunghyun Cho，Bart vanMerriënboerCaglar Gulcehre，Dzmitry Bahdanau，Fethi Bougares Holger Schwenk和Yoshua Bengio。学习使用RNN编码器 - 解码器进行统计机器翻译的短语表示。 EMNLP（2014），1724-1734。 
 [7]GünesErkan和Dragomir R Radev。 Lexrank：基于图形的词汇中心 -  
 作为文本总结中的显着性。 JAIR 22（2004），457-479。 Ian Goodfellow，Yoshua Bengio和Aaron Courville。深度学习。 MIT出版社。 http://www.deeplearningbook.org。 Ian Goodfellow，Jean Pouget-Abadie，Mehdi Mirza，Bing Xu，David Warde-Farley，Sherjil Ozair，Aaron Courville和Yoshua Bengio。生成敌对网。在NIPS。 2672至2680年。 
 [10]何湘南，陈涛，阚敏燕，肖晨。 Trirank：Reviewaware通过建模方面的可解释建议。在CIKM。 ACM，1661-1670。 
 [11]何湘南，廖立子，张汉旺，聂力强，胡霞，达生 
 蔡细历。 2017年。神经协同过滤。在WWW。 173-182。 
 [12] Sepp Hochreiter和JürgenSchmidhuber。长期的短期记忆。神经 
 [13] Philipp Koehn。 Pharaoh：用于基于短语的统计机器翻译模型的波束搜索解码器。在美洲机器翻译协会会议上。施普林格，115-124。 
 [14]耶胡达科伦。分解与邻域相遇：多方面 
 协同过滤模型。在KDD。 ACM，426-434。 
 [15]耶胡达克伦，罗伯特贝尔，克里斯沃林斯基等人。 2009年矩阵分解 
 推荐系统技术。计算机42,8（2009），30-37。 
 [16] Alex Krizhevsky，Ilya Sutskever和Geoffrey E Hinton。 Imagenet classifi- 
 阳离子与深卷积神经网络。在NIPS。 1097-1105。 
 [17] Quoc V Le和Tomas Mikolov。 2014.句子的分布式表示 
 [18]丹尼尔D李和H塞巴斯蒂安。 2001.非负矩阵的算法 
 [19]李皮基，王子豪，韦伟林，赵肇伦，李东兵。通过变分自动编码器进行多文档摘要的显着性估计。在AAAI。 3497-3503。 
 [20]金 - 林。 2004年。Rouge：用于自动评估总结的软件包。 
 [21] Guang Ling，Michael R Lyu和Irwin King。评分满足评论，a 
 结合办法推荐。在RecSys中。 105-112。 
 [22]本杰明M马林。为协作过滤建模用户评级配置文件。 
 在NIPS。 627-634。朱利安麦考利和Jure Leskovec。隐藏的因素和隐藏的主题：使用评论文字理解评分维度。在RecSys中。 ACM，165-172。 
 [24] Tomas Mikolov，Ilya Sutskever，Kai Chen，Greg S Corrado和Jeff Dean。分词表达的单词和短语及其组合性。在NIPS。 3111-3119。 
 [25] Andrew Ng。稀疏自动编码器。 CS294A讲义72（2011），1-19。 [17]赵肇仁，尚松良，李丕基，王帅强，马尔滕德里克。社会协作观点回归与可解释的建议。在WSDM中。 
 [27]弗朗切斯科利玛窦，利奥罗卡赫和布拉恰夏皮拉。推荐的介绍， 
 [28]弗兰克罗森布拉特。 1961年。神经动力学原理。感知器和理论 
 的脑机制。技术报告。 DTIC文件。 
 [29] David E Rumelhart，Geoffrey E Hinton和Ronald J Williams。 1988年。通过向后传播错误学习表示。认知模型5,3（1988），1。[30]亚历山大M拉什，住友乔普拉和杰森韦斯顿。神经的关注 
 抽象句汇总模型。在EMNLP。 
 [31] Ruslan Salakhutdinov和Andriy Mnih。概率矩阵分解.. 
 [32] Ruslan Salakhutdinov，Andriy Mnih和Geoffrey Hinton。 2007.受限制 
 玻尔兹曼机器进行协作过滤。在ICML中。 ACM，791-798。 
 [33]巴德鲁萨尔瓦，乔治卡里皮斯，约瑟夫康斯坦和约翰里德尔。基于项目的协同过滤推荐算法。在WWW。 ACM，285-295。 Suvash Sedhain，Aditya Krishna Menon，Scott Sanner和Lexing Xie。 Autorec：自动编码器符合协作过滤。在WWW。 ACM，111-112。 [35]乐士，玛莎拉森和艾伦汉加利奇。列表学习与排名 
 矩阵分解用于协作过滤。在RecSys中。 269-272。 
 [36]理查德瑟瑟，陈丹琪，克里斯托弗D曼宁和安德鲁吴。用知识库完成的神经张量网络进行推理。在NIPS。 926-934。 
 [38]苏小园和塔吉M Khoshgoftaar。协作过滤调查 
 技术。人工智能进展2009（2009），4。 
 Theano开发团队。 Theano：一个用于快速计算的Python框架， 
 数学表达式。 arXiv电子打印abs / 1605.02688（2016）。 
 [39] Pascal Vincent，Hugo Larochelle，Isabelle Lajoie，Yoshua Bengio和PierreAntoine Manzagol。 2010.叠加去噪自动编码器：使用本地去噪标准在深度网络中学习有用的表示。 JMLR 11（2010），3371-3408。 
 [40] Chong Wang和David M Blei。合作主题建模， 
 修补科学文章。在KDD。 ACM，448-456。 
 [41]王皓，王乃炎，杨雁燕。 2015年。协作深度学习 
 推荐系统。在KDD。 ACM，1235-1244。 
 [42]王昊，史行健，杨雁燕。合作经常性自动编码器：在学习填写空白时推荐。在NIPS。 415-423。 [43]赵超远，阿姆艾哈迈德，亚历克斯Beutel，亚历山大J斯莫拉，和何晶。 
 经常性推荐网络。在WSDM中。 495-503页。 
 [44]姚武，克里斯托弗杜波伊斯，艾丽斯X郑和马丁艾斯特。协作去噪自动编码器，用于top-n推荐系统。在WSDM中。 ACM，153-162。 
 [45]吴永辉，迈克舒斯特，陈志丰，国乐乐，穆罕默德诺鲁齐，沃尔夫冈马克雷，马克斯克里克，曹操，秦高，克劳斯马克雷伊等。 Google的神经机器翻译系统：弥合人机翻译之间的差距。 arXiv预印本arXiv：1609.08144（2016）。 
 [46]徐银青，韦伟林，林天一。 2014年。协作过滤，包含隐藏的用户社区和项目组的审阅文本和联合群集。在CIKM。 ACM，251-260。 
 [47]许银青，贝诗，田文涛，韦琳。一个统一的模型，用于包含文本通用性的无监督意见垃圾邮件检测。在IJCAI。 725-731。 
 [48] Matthew D Zeiler。 ADADELTA：自适应学习率方法。的arXiv 
 [49]雷政，Vahid Noroozi和Philip S Yu。 2017年。联合用户深度建模 
 以及使用评论进行推荐的项目。在WSDM中。 ACM，425-434。 
